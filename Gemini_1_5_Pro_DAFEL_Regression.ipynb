{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bqMK4Xejpfj",
        "outputId": "2cc77b91-a6b7-4502-fcc0-ebef3c5d8332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_folder_path = \"/content/drive/My Drive/datasets/Regression/\"\n"
      ],
      "metadata": {
        "id": "Jz5riiU_j0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Get list of all CSV files in the folder\n",
        "csv_files = glob.glob(os.path.join(csv_folder_path, \"*.csv\"))\n",
        "print(csv_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJAtIf0gosqI",
        "outputId": "b55cd770-c40a-44fc-8eeb-895b6d5c0cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/My Drive/datasets/Regression/AirfoilSelfNoise.csv', '/content/drive/My Drive/datasets/Regression/CrabAgePrediction.csv', '/content/drive/My Drive/datasets/Regression/forestfires.csv', '/content/drive/My Drive/datasets/Regression/US_Health_Insurance.csv', '/content/drive/My Drive/datasets/Regression/cpu_small.csv', '/content/drive/My Drive/datasets/Regression/bike_hour.csv', '/content/drive/My Drive/datasets/Regression/Diamonds Prices2022.csv', '/content/drive/My Drive/datasets/Regression/winequalitywhite1.csv', '/content/drive/My Drive/datasets/Regression/plasma_retinol.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "import ast\n",
        "import time\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get free API key from https://aistudio.google.com/app/apikey\n",
        "GOOGLE_API_KEY = userdata.get(\"Google_API_2\")  # Replace with your key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Initialize Gemini model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "def nrmse_by_mean(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute Normalized Root Mean Squared Error (nRMSE),\n",
        "    normalized by the mean of y_true.\n",
        "    \"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mean_y = np.mean(y_true)\n",
        "    return rmse / mean_y if mean_y != 0 else float('inf')\n",
        "\n",
        "\n",
        "class LLMFE:\n",
        "    def __init__(self, data, target_column, metric=nrmse_by_mean, max_iter=50):\n",
        "        self.data = data\n",
        "        self.target = target_column\n",
        "        self.metric = metric\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        # Split data\n",
        "        self.train, self.val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "        self.X_train = self.train.drop(target_column, axis=1)\n",
        "        self.y_train = self.train[target_column]\n",
        "        self.X_val = self.val.drop(target_column, axis=1)\n",
        "        self.y_val = self.val[target_column]\n",
        "\n",
        "        # Memory buffers\n",
        "        self.memory = []\n",
        "        self.best_score = float('inf')\n",
        "        self.best_transformation = None\n",
        "\n",
        "    def _create_prompt(self):\n",
        "\n",
        "          # ===== PHASE 1: FEATURE SELECTION =====\n",
        "      feature_selection_prompt = f\"\"\"\n",
        "      **PHASE 1: Feature Selection for '{self.target}'**\n",
        "\n",
        "      Dataset: {os.path.basename(self.data.attrs.get('filename', 'unknown'))}\n",
        "      Features: {list(self.X_train.columns)}\n",
        "\n",
        "      Instructions:\n",
        "      1. Analyze features using:\n",
        "       - Correlation (keep if |r| > 0.15)\n",
        "       - Domain knowledge (e.g., \"carat\" matters for diamond prices)\n",
        "       - Variance (drop if >95% same value)\n",
        "      2. Flag redundant features (drop if r > 0.8 with more important feature)\n",
        "\n",
        "      Required Output:\n",
        "      ```python\n",
        "      # Features to KEEP (high relevance):\n",
        "      keep = ['feature1', 'feature2']\n",
        "\n",
        "      # Features to DROP:\n",
        "      drop = ['id', 'constant_feature']\n",
        "\n",
        "      # Potential interaction terms:\n",
        "      interactions = [('feature1', 'feature2')]\n",
        "      ```\n",
        "      \"\"\"\n",
        "    # Dataset-specific guidance\n",
        "      dataset_guidance = {\n",
        "        \"Diamonds Prices2022.csv\": {\n",
        "            \"hint\": \"Consider transformations involving carat, cut quality, and physical dimensions (x,y,z).\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(volume=df['x'] * df['y'] * df['z'])\",\n",
        "                \"lambda df: df.assign(carat_per_depth=df['carat'] / df['depth'])\",\n",
        "                \"lambda df: df.assign(cut_encoded=df['cut'].map({'Fair':1, 'Good':2, 'Very Good':3, 'Premium':4, 'Ideal':5}))\"\n",
        "            ]\n",
        "        },\n",
        "        \"winequalitywhite1.csv\": {\n",
        "          \"hint\": \"Consider transformations involving acidity, sugar, sulfur compounds, and alcohol levels.\",\n",
        "          \"examples\": [\n",
        "              \"lambda df: df.assign(sugar_to_acidity_ratio=df['residual sugar'] / df['fixed acidity'])\",\n",
        "              \"lambda df: df.assign(total_acidity=df['fixed acidity'] + df['volatile acidity'] + df['citric acid'])\",\n",
        "              \"lambda df: df.assign(sulfur_ratio=df['free sulfur dioxide'] / df['total sulfur dioxide'])\",\n",
        "              \"lambda df: df.assign(alcohol_density_ratio=df['alcohol'] / df['density'])\"\n",
        "          ]\n",
        "      },\n",
        "        \"plasma_retinol.csv\": {\n",
        "          \"hint\": \"Consider transformations involving age, BMI, dietary intake, and cholesterol levels.\",\n",
        "          \"examples\": [\n",
        "            \"lambda df: df.assign(bmi_age_ratio=df['bmi'] / df['age'])\",\n",
        "            \"lambda df: df.assign(fat_to_calories_ratio=df['fat'] / df['calories'])\",\n",
        "            \"lambda df: df.assign(cholesterol_per_bmi=df['cholesterol'] / df['bmi'])\",\n",
        "            \"lambda df: df.assign(age_squared=df['age'] ** 2)\"\n",
        "          ]\n",
        "      },\n",
        "        \"AirfoilSelfNoise.csv\": {\n",
        "            \"hint\": \"Consider aerodynamic interactions between frequency, angle of attack, and flow velocity.\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(reynolds=df['U_infinity'] * df['c'] / 1.5e-5)\",  # Approx kinematic viscosity of air\n",
        "                \"lambda df: df.assign(strouhal=df['f'] * df['c'] / (df['U_infinity'] + 1e-9))\",  # Small value to avoid div/0\n",
        "                \"lambda df: df.assign(angle_velocity_ratio=df['alpha'] / (df['U_infinity'] + 1e-9))\"\n",
        "            ]\n",
        "        },\n",
        "        \"CrabAgePrediction.csv\": {\n",
        "            \"hint\": \"Consider ratios between different weight measurements and size dimensions.\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(shell_ratio=df['Shell Weight'] / df['Weight'])\",\n",
        "                \"lambda df: df.assign(size_to_weight=df['Length'] * df['Diameter'] / df['Weight'])\",\n",
        "                \"lambda df: df.assign(meat_yield=(df['Shucked Weight'] + df['Viscera Weight']) / df['Weight'])\"\n",
        "            ]\n",
        "        },\n",
        "        \"forestfires.csv\": {\n",
        "            \"hint\": \"Consider interactions between weather conditions and temporal factors.\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(fire_risk_index=df['temp'] * df['wind'] / (df['RH'] + 1))\",\n",
        "                \"lambda df: df.assign(drought_index=df['DMC'] * df['DC'])\",\n",
        "                \"lambda df: df.assign(month_encoded=pd.to_datetime(df['month'], format='%b').dt.month)\"\n",
        "            ]\n",
        "        },\n",
        "        \"US_Health_Insurance.csv\": {\n",
        "            \"hint\": \"Consider interactions between BMI, smoking status, and age.\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(bmi_age=df['bmi'] * df['age'])\",\n",
        "                \"lambda df: df.assign(smoker_encoded=df['smoker'].map({'yes':1, 'no':0}))\",\n",
        "                \"lambda df: df.assign(risk_factor=np.where(df['smoker']=='yes', df['bmi']*df['age'], df['bmi']))\"\n",
        "            ]\n",
        "        },\n",
        "        \"cpu_small.csv\": {\n",
        "            \"hint\": \"Consider ratios between different system operations and resource usage.\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(io_ratio=df['lread'] / (df['lwrite'] + 1))\",\n",
        "                \"lambda df: df.assign(mem_pressure=df['freemem'] / (df['freeswap'] + 1))\",\n",
        "                \"lambda df: df.assign(syscall_efficiency=df['exec'] / (df['scall'] + 1))\"\n",
        "            ]\n",
        "        },\n",
        "        \"bike_hour.csv\": {\n",
        "            \"hint\": \"Consider temporal patterns and weather interactions.\",\n",
        "            \"examples\": [\n",
        "                \"lambda df: df.assign(temp_feel=df['temp'] * df['hum'])\",\n",
        "                \"lambda df: df.assign(hour_sin=np.sin(2 * np.pi * df['hr'] / 24))\",\n",
        "                \"lambda df: df.assign(workday_weather=df['workingday'] * df['weathersit'])\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Get filename for guidance lookup\n",
        "      filename = os.path.basename(self.data.attrs.get('filename', 'unknown'))\n",
        "\n",
        "    # Get dataset-specific guidance or use defaults\n",
        "      guidance = dataset_guidance.get(filename, {\n",
        "        \"hint\": \"Consider interactions between numerical features and encodings for categoricals.\",\n",
        "        \"examples\": [\n",
        "            \"lambda df: df.assign(feature1_squared=df['feature1'] ** 2)\",\n",
        "            \"lambda df: df.assign(feature_ratio=df['feature1'] / (df['feature2'] + 1e-9))\",\n",
        "            \"lambda df: df.assign(cat_encoded=df['category'].map({'A':1, 'B':2, 'C':3}))\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "      return f\"\"\"\n",
        "      You are a feature engineering expert working with a dataset to predict '{self.target}'.\n",
        "      The available features are: {list(self.X_train.columns)}\n",
        "\n",
        "      Dataset-specific guidance: {guidance['hint']}\n",
        "\n",
        "      Current best score (NMSE): {self.best_score:.4f}\n",
        "\n",
        "      Here are some relevant transformation examples for this dataset:\n",
        "      {chr(10).join(guidance['examples'])}\n",
        "\n",
        "      Please suggest 3 novel, computationally efficient feature transformations that would help predict '{self.target}'.\n",
        "      Focus on creating meaningful interactions between features or transformations that might reveal non-linear relationships.\n",
        "\n",
        "      Format each transformation as a Python lambda function:\n",
        "      lambda df: df.assign(<new_feature_name>=<transformation_expression>)\n",
        "\n",
        "      Requirements:\n",
        "      1. Each transformation should be a single line\n",
        "      2. Avoid extremely complex expressions that might cause numerical instability\n",
        "      3. Include comments explaining the transformation when appropriate\n",
        "      \"\"\"\n",
        "\n",
        "    def generate_transformations(self):\n",
        "        prompt = self._create_prompt()\n",
        "        response = model.generate_content(prompt)\n",
        "        return self._parse_response(response.text)\n",
        "\n",
        "    def _parse_response(self, text):\n",
        "        transformations = []\n",
        "        for line in text.split('\\n'):\n",
        "            if line.startswith('lambda'):\n",
        "                try:\n",
        "                    ast.parse(line)\n",
        "                    transformations.append(line.strip())\n",
        "                except SyntaxError:\n",
        "                    continue\n",
        "        return transformations[:3]\n",
        "\n",
        "    def evaluate_transformation(self, transformation):\n",
        "        try:\n",
        "            func = eval(transformation) # checks if the transformation is a valid python expression or not.\n",
        "\n",
        "            # Apply transformation\n",
        "            X_train_trans = func(self.X_train.copy())\n",
        "            X_val_trans = func(self.X_val.copy())\n",
        "\n",
        "            # Encode categorical features\n",
        "            for col in X_train_trans.select_dtypes(include=['object']).columns:\n",
        "                X_train_trans[col], uniques = pd.factorize(X_train_trans[col])\n",
        "                X_val_trans[col] = X_val_trans[col].map({val: idx for idx, val in enumerate(uniques)}).fillna(-1)\n",
        "\n",
        "            # Train model\n",
        "            model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
        "            model.fit(X_train_trans, self.y_train)\n",
        "            preds = model.predict(X_val_trans)\n",
        "\n",
        "            # Calculate NMSE score\n",
        "            score = self.metric(self.y_val, preds)\n",
        "\n",
        "            return {\n",
        "                'score': score,\n",
        "                'transformation': transformation,\n",
        "                'features': list(X_train_trans.columns)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in transformation: {e}\")\n",
        "            return None\n",
        "\n",
        "    def run(self):\n",
        "        for iteration in range(self.max_iter):\n",
        "            print(f\"\\n--- Iteration {iteration+1}/{self.max_iter} ---\")\n",
        "\n",
        "            # Generate transformations\n",
        "            transformations = self.generate_transformations()\n",
        "            print(f\"Generated {len(transformations)} transformations\")\n",
        "\n",
        "            # Evaluate transformations\n",
        "            results = [self.evaluate_transformation(t) for t in transformations]\n",
        "\n",
        "            # Update memory\n",
        "            for result in results:\n",
        "                if result and result['score'] < self.best_score:\n",
        "                    self.best_score = result['score']\n",
        "                    self.best_transformation = result['transformation']\n",
        "                    self.memory.append(result)\n",
        "                    func = eval(self.best_transformation)\n",
        "                    self.X_train = func(self.X_train.copy())\n",
        "                    self.X_val = func(self.X_val.copy())\n",
        "\n",
        "            print(f\"Current Best NRMSE: {self.best_score:.4f}\")\n",
        "\n",
        "        return self.best_transformation, self.best_score"
      ],
      "metadata": {
        "id": "c4Q2zjN7tntl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "for csv_file in csv_files:\n",
        "    try:\n",
        "        print(f\"\\nðŸ“‚ Processing file: {csv_file}\")\n",
        "        data = pd.read_csv(csv_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        print(\"Columns in the dataset:\", list(data.columns))\n",
        "        target_col = input(\"ðŸ‘‰ Please enter the name of the target column: \").strip()\n",
        "\n",
        "        if target_col not in data.columns:\n",
        "            print(f\"âŒ Column '{target_col}' not found in dataset. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"ðŸŽ¯ Using target column: {target_col}\")\n",
        "\n",
        "        # Run the LLMFE pipeline\n",
        "        fe = LLMFE(data=data, target_column=target_col, max_iter=3)\n",
        "        best_trans, best_score = fe.run()\n",
        "\n",
        "        print(f\"\\nâœ… Done: {os.path.basename(csv_file)}\")\n",
        "        print(f\"ðŸ” Best Transformation: {best_trans}\")\n",
        "        print(f\"ðŸ“‰ Validation NRMSE: {best_score:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing {csv_file}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y3udlAposg37",
        "outputId": "23588d1a-3813-43cb-e7d1-e54e44b99373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/AirfoilSelfNoise.csv\n",
            "Columns in the dataset: ['f', 'alpha', 'c', 'U_infinity', 'delta', 'SSPL']\n",
            "ðŸ‘‰ Please enter the name of the target column: SSPL\n",
            "ðŸŽ¯ Using target column: SSPL\n",
            "\n",
            "--- Iteration 1/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 0.0133\n",
            "\n",
            "--- Iteration 2/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 0.0133\n",
            "\n",
            "--- Iteration 3/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 0.0133\n",
            "\n",
            "âœ… Done: AirfoilSelfNoise.csv\n",
            "ðŸ” Best Transformation: lambda df: df.assign(f_alpha_scaled=df['f'] * df['alpha'] / (df['U_infinity'] + 1e-9))\n",
            "ðŸ“‰ Validation NRMSE: 0.0133\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/CrabAgePrediction.csv\n",
            "Columns in the dataset: ['Sex', 'Length', 'Diameter', 'Height', 'Weight', 'Shucked Weight', 'Viscera Weight', 'Shell Weight', 'Age']\n",
            "ðŸ‘‰ Please enter the name of the target column: Age\n",
            "ðŸŽ¯ Using target column: Age\n",
            "\n",
            "--- Iteration 1/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 0.2164\n",
            "\n",
            "--- Iteration 2/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 0.2075\n",
            "\n",
            "--- Iteration 3/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 0.2074\n",
            "\n",
            "âœ… Done: CrabAgePrediction.csv\n",
            "ðŸ” Best Transformation: lambda df: df.assign(length_diameter_height_weight_interaction = (df['Length'] * df['Diameter'] * df['Height']) / (df['Weight'] + 1e-9))\n",
            "ðŸ“‰ Validation NRMSE: 0.2074\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/forestfires.csv\n",
            "Columns in the dataset: ['X', 'Y', 'month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area']\n",
            "ðŸ‘‰ Please enter the name of the target column: area\n",
            "ðŸŽ¯ Using target column: area\n",
            "\n",
            "--- Iteration 1/3 ---\n",
            "Generated 0 transformations\n",
            "Current Best NRMSE: inf\n",
            "\n",
            "--- Iteration 2/3 ---\n",
            "Generated 3 transformations\n",
            "Current Best NRMSE: 5.5182\n",
            "\n",
            "--- Iteration 3/3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 964.70ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error processing /content/drive/My Drive/datasets/Regression/forestfires.csv: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/US_Health_Insurance.csv\n",
            "Columns in the dataset: ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
            "ðŸ‘‰ Please enter the name of the target column: charges\n",
            "ðŸŽ¯ Using target column: charges\n",
            "\n",
            "--- Iteration 1/3 ---\n",
            "Generated 0 transformations\n",
            "Current Best NRMSE: inf\n",
            "\n",
            "--- Iteration 2/3 ---\n",
            "Generated 0 transformations\n",
            "Current Best NRMSE: inf\n",
            "\n",
            "--- Iteration 3/3 ---\n",
            "Generated 0 transformations\n",
            "Current Best NRMSE: inf\n",
            "\n",
            "âœ… Done: US_Health_Insurance.csv\n",
            "ðŸ” Best Transformation: None\n",
            "ðŸ“‰ Validation NRMSE: inf\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/cpu_small.csv\n",
            "Columns in the dataset: ['lread', 'lwrite', 'scall', 'sread', 'swrite', 'fork', 'exec', 'rchar', 'wchar', 'runqsz', 'freemem', 'freeswap', 'usr']\n",
            "ðŸ‘‰ Please enter the name of the target column: usr\n",
            "ðŸŽ¯ Using target column: usr\n",
            "\n",
            "--- Iteration 1/3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 709.91ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error processing /content/drive/My Drive/datasets/Regression/cpu_small.csv: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/bike_hour.csv\n",
            "Columns in the dataset: ['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']\n",
            "ðŸ‘‰ Please enter the name of the target column: hr\n",
            "ðŸŽ¯ Using target column: hr\n",
            "\n",
            "--- Iteration 1/3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 760.52ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error processing /content/drive/My Drive/datasets/Regression/bike_hour.csv: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/Diamonds Prices2022.csv\n",
            "Columns in the dataset: ['Id', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
            "ðŸ‘‰ Please enter the name of the target column: price\n",
            "ðŸŽ¯ Using target column: price\n",
            "\n",
            "--- Iteration 1/3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 762.85ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error processing /content/drive/My Drive/datasets/Regression/Diamonds Prices2022.csv: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/winequalitywhite1.csv\n",
            "Columns in the dataset: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
            "ðŸ‘‰ Please enter the name of the target column: quality\n",
            "ðŸŽ¯ Using target column: quality\n",
            "\n",
            "--- Iteration 1/3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 636.32ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error processing /content/drive/My Drive/datasets/Regression/winequalitywhite1.csv: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "\n",
            "ðŸ“‚ Processing file: /content/drive/My Drive/datasets/Regression/plasma_retinol.csv\n",
            "Columns in the dataset: ['AGE', 'SEX', 'SMOKSTAT', 'QUETELET', 'VITUSE', 'CALORIES', 'FAT', 'FIBER', 'ALCOHOL', 'CHOLESTEROL', 'BETADIET', 'RETDIET', 'BETAPLASMA', 'RETPLASMA']\n",
            "ðŸ‘‰ Please enter the name of the target column: RETPLASMA\n",
            "ðŸŽ¯ Using target column: RETPLASMA\n",
            "\n",
            "--- Iteration 1/3 ---\n",
            "âŒ Error processing /content/drive/My Drive/datasets/Regression/plasma_retinol.csv: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 814.42ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pN1sCtGluM15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}